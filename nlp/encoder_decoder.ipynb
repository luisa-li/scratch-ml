{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from d2l import torch as d2l\n",
    "from vocab import Vocab\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/fra-eng/fra.txt\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "    no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text.lower())]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go .\\tva !\\nhi .\\tsalut !\\nrun !\\tcours !\\nrun !\\tcourez !\\nwho ?\\tqui ?\\nwow !\\tça alors !\\nfire !\\tau feu !\\nhel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocess(raw_text)\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Turn the raw text into a tuple[list[list[str]]], where the outer\n",
    "    tuple\n",
    "    \"\"\"\n",
    "    eng, fra = [], []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) == 2:\n",
    "            p1, p2 = parts[0], parts[1]\n",
    "            eng.append(p1.split(\" \") + [\"<eos>\"])\n",
    "            fra.append(p2.split(\" \") + [\"<eos>\"])        \n",
    "    return (eng, fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go', '.', '<eos>'],\n",
       " ['hi', '.', '<eos>'],\n",
       " ['run', '!', '<eos>'],\n",
       " ['run', '!', '<eos>'],\n",
       " ['who', '?', '<eos>'],\n",
       " ['wow', '!', '<eos>'],\n",
       " ['fire', '!', '<eos>'],\n",
       " ['help', '!', '<eos>'],\n",
       " ['jump', '.', '<eos>'],\n",
       " ['stop', '!', '<eos>']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenize(text)\n",
    "tokenized[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further prepping the data, first just the english part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnglishDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167130/167130 [00:01<00:00, 157630.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5906, 153, 424], [6459, 153, 424], [11242, 0, 424], [11242, 0, 424], [14551, 426, 424]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# have to convert to integers oops \n",
    "eng = Vocab(tokenized[0])\n",
    "indeces = []\n",
    "for line in tqdm(tokenized[0]):\n",
    "    indeces.append(eng[line])\n",
    "print(indeces[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the english dictionary to get all the sequences to be of the same size\n",
    "def pad(seq, length):\n",
    "    \"\"\"Pads the sequence to the appropriate length and returns the mask\"\"\"\n",
    "    padding = length - len(seq)\n",
    "    masking = [1] * len(seq) + [0] * padding\n",
    "    return seq + [0] * padding, masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the dataset \n",
    "inputs, masks = [], []\n",
    "longest = max([len(line) for line in indeces])\n",
    "for line in indeces:\n",
    "    input, mask = pad(line, longest)\n",
    "    inputs.append(input)\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    batched = torch.tensor(data)\n",
    "    print(batched)\n",
    "    return batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "dataset = EnglishDataset(inputs)\n",
    "data_iter = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True, collate_fn=batchify, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to create a LSTM encoder only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        return output, hidden, cell # actual output, short term memory, long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2515453892.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[49], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    trg_input =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        # TODO: FINISH THIS PART AND SEE HOW THE ENCODER WOULD CONNECT TO THE DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(eng)\n",
    "embedding_size = 10\n",
    "hidden_dim = 32\n",
    "dropout = 0.1\n",
    "device = 'cpu'\n",
    "encoder = Encoder(input_dim, embedding_size, hidden_dim, dropout)\n",
    "criterion = nn.MSELoss()  # Example loss function\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
